{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylkKhoN5D1VM"
      },
      "source": [
        "# DNN 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mjTc-pjDoPD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qj0_KLwbD0cf"
      },
      "outputs": [],
      "source": [
        "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# 정규화\n",
        "train_x = raw_train_x/255.\n",
        "test_x = raw_test_x/255.\n",
        "\n",
        "train_y = raw_train_y\n",
        "test_y = raw_test_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Fw7YATeD0e8"
      },
      "outputs": [],
      "source": [
        "# DNN 모델\n",
        "model = keras.Sequential()\n",
        "model.add(Input((28,28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "# 학습\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "# 성능 평가\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "# 예측\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU5Xvu8EOsNl"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ7e4X0vD0hR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input, Reshape\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZoh6n-XD0jw"
      },
      "outputs": [],
      "source": [
        "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# 정규화\n",
        "train_x = raw_train_x/255.\n",
        "test_x = raw_test_x/255.\n",
        "\n",
        "train_y = raw_train_y\n",
        "test_y = raw_test_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7gN6JTlD0lr"
      },
      "outputs": [],
      "source": [
        "# CNN 모델\n",
        "model = keras.Sequential()\n",
        "model.add(Input((28,28)))\n",
        "model.add(Reshape((28,28,1))) # ADD <---------------\n",
        "model.add(Conv2D(32, (3, 3), padding='same')) # ADD <---------------\n",
        "model.add(MaxPooling2D((2, 2))) # ADDED\n",
        "model.add(Conv2D(64, (3, 3), padding='same')) # ADD <---------------\n",
        "model.add(MaxPooling2D((2, 2))) # ADD <---------------\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "# 학습\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "# 예측\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDlenwMJPMao"
      },
      "source": [
        "conv2d 레이어의 파라매터 수는 다음에 의해서 결정된다.\n",
        "```\n",
        "파라매터 수 = (conv필터 가로 * conv 필터 세로 * 데이터 깊이 + bias 1개) * 필터 수\n",
        "```\n",
        "위 모델의 경우 파라매터 수 320, 18496은 다음과 같이 결정된다.\n",
        "\n",
        "```\n",
        "320 = (3*3*1+1) * 32\n",
        "\n",
        "18496 = (3*3*32+1)*64\n",
        "```\n",
        "\n",
        "```\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
        "_________________________________________________________________\n",
        "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
        "_________________________________________________________________\n",
        "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqbvaeiVtUIF"
      },
      "source": [
        "# 영상 데이터 분류 CNN Template 한번에 보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy1p8uiiD0qB",
        "outputId": "61fa4e3c-36c9-4eab-c3f0-aac1ec41f574"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                16010     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,046\n",
            "Trainable params: 35,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 55s 113ms/step - loss: 0.5194 - accuracy: 0.8385\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 46s 98ms/step - loss: 0.1493 - accuracy: 0.9561\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 47s 101ms/step - loss: 0.1076 - accuracy: 0.9682\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 46s 99ms/step - loss: 0.0868 - accuracy: 0.9739\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 46s 99ms/step - loss: 0.0736 - accuracy: 0.9776\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0812 - accuracy: 0.9746\n",
            "loss= 0.0811741054058075\n",
            "acc= 0.9746000170707703\n",
            "[7 2 1 ... 4 5 6]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input, Reshape\n",
        "\n",
        "import time\n",
        "\n",
        "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_x = raw_train_x/255.\n",
        "test_x = raw_test_x/255.\n",
        "\n",
        "train_y = raw_train_y\n",
        "test_y = raw_test_y\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(Input((28,28)))\n",
        "model.add(Reshape((28,28,1)))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXuIHQaXD0sU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q58N7droD0uN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Krdqqa-bD0wO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7QYNiErD0yH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8EQtreLD00M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3XgF5lED02H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WXtaK18D038"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ry16u_GiD06G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNweFL0CD08R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "06_CNN(MNIST_data이용).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
